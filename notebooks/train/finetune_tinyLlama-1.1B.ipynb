{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d097bd4f-c8ea-4787-8ac1-91152086a0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers accelerate peft datasets pandas scikit-learn numpy matplotlib\n",
    "!pip install -q bitsandbytes safetensors\n",
    "\n",
    "!pip install -q awscli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4a1cf2-55c7-4731-a816-7d066fd17b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset size: 85000\n",
      "Sample prompts: [\"Generate Python code for: Pelvic Girdle Pain during or after Pregnancy: a review of recent evidence and a clinical care path proposal\\nAbstract: PROBLEM STATEMENT\\nPelvic girdle pain (PGP) is a common condition during or after pregnancy with pain and disability as most important symptoms. These symptoms have a wide range of clinical presentation. Most doctors perceive pregnancy related pelvic girdle pain (PPGP) as 'physiologic' or 'expected during pregnancy', where no treatment is needed. As such women with PPGP mostly experience little rec\", 'Generate Python code for: Packet Classification Using Tuple Space Search\\nAbstract: Routers must perform packet classification at high speeds to efficiently implement functions such as firewalls and QoS routing. Packet classification requires matching each packet against a database of filters (or rules), and forwarding the packet according to the highest priority filter. Existing filter schemes with fast lookup time do not scale to large filter databases. Other more scalable sche', 'Generate Python code for: Bayesian Compressive Sensing\\nAbstract: The data of interest are assumed to be represented as N-dimensional real vectors, and these vectors are compressible in some linear basis B, implying that the signal can be reconstructed accurately using only a small number M Lt N of basis-function coefficients associated with B. Compressive sensing is a framework whereby one does not measure one of the aforementioned N-dimensional signals directl']\n",
      "Sample codes: ['import numpy as np\\nimport scipy\\nfrom scipy import stats\\n\\nfrom networkx.algorithms import bipartite\\ni...', '#!/usr/bin/env python\\n# -*- coding: utf-8 -*-\\n# @Time    : 5/15/20 4:49 PM\\n# @File    : grover.py\\n\\n#...', '# This file is part of the pyMOR project (http://www.pymor.org).\\n# Copyright 2013-2020 pyMOR develop...']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import subprocess\n",
    "from datasets import Dataset, load_dataset\n",
    "from typing import List\n",
    "\n",
    "def prepare_datasets() -> Dataset:\n",
    "    \"\"\"Prepare dataset using only real data sources\"\"\"\n",
    "    all_prompts: List[str] = []\n",
    "    all_codes: List[str] = []\n",
    "    \n",
    "    def load_scidocs() -> List[str]:\n",
    "        try:\n",
    "            os.makedirs(\"scidocs_data\", exist_ok=True)\n",
    "            if not os.path.exists(\"scidocs_data/paper_metadata_view_cite_read.json\"):\n",
    "                subprocess.run([\n",
    "                    \"aws\", \"s3\", \"sync\", \"--no-sign-request\",\n",
    "                    \"s3://ai2-s2-research-public/specter/scidocs/\",\n",
    "                    \"scidocs_data/\", \"--region\", \"us-west-2\", \"--quiet\"\n",
    "                ], check=True)\n",
    "            \n",
    "            with open(\"scidocs_data/paper_metadata_view_cite_read.json\", \"r\") as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            prompts = []\n",
    "            for paper_id, content in data.items():\n",
    "                title = content.get('title', '') or ''\n",
    "                abstract = content.get('abstract', '') or ''\n",
    "                \n",
    "                if len(title) > 10 and len(abstract) > 200:\n",
    "                    prompts.append(\n",
    "                        f\"Generate Python code for: {title}\\nAbstract: {abstract[:400]}\"\n",
    "                    )\n",
    "            return prompts\n",
    "        except Exception as e:\n",
    "            print(f\"SciDocs loading failed: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "    def load_astronomy() -> List[str]:\n",
    "        try:\n",
    "            ds = load_dataset(\"David-Xu/astronomy-stack-dpo-text\", split=\"train\")\n",
    "            return [example['prompt'] for example in ds]\n",
    "        except Exception as e:\n",
    "            print(f\"Astronomy dataset loading failed: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "    def load_science() -> List[str]:\n",
    "        try:\n",
    "            ds = load_dataset(\"millawell/wikipedia_field_of_science\", split=\"train\")\n",
    "            return [text for text in ds['text'] if len(text) > 30]\n",
    "        except Exception as e:\n",
    "            print(f\"Science dataset loading failed: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "    def load_code_samples() -> List[str]:\n",
    "        try:\n",
    "            ds = load_dataset(\"bigcode/the-stack\", \n",
    "                            data_dir=\"data/python\", \n",
    "                            split=\"train\",\n",
    "                            streaming=True)\n",
    "            \n",
    "            samples = []\n",
    "            for sample in ds:\n",
    "                content = sample[\"content\"]\n",
    "                if any(imp in content for imp in [\"numpy\", \"sklearn\", \"pandas\", \"matplotlib\"]):\n",
    "                    if \"auto-generated\" not in content.lower():\n",
    "                        samples.append(content[:2000])\n",
    "                        if len(samples) >= 20000:\n",
    "                            break\n",
    "            return samples\n",
    "        except Exception as e:\n",
    "            print(f\"Code dataset loading failed: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "    scidocs = load_scidocs()[:25000]  # Cap at 25k\n",
    "    astronomy = load_astronomy()[:15000]  # Cap at 15k\n",
    "    science = load_science()[:15000]  # Cap at 15k\n",
    "    code_samples = load_code_samples()[:20000]  # Cap at 20k\n",
    "    \n",
    "    science_code_prompts = [\n",
    "        f\"Generate Python code for: {text.split(':')[-1].strip()}\" \n",
    "        for text in science[:10000]\n",
    "    ]\n",
    "\n",
    "    # Combine all sources\n",
    "    all_prompts.extend(scidocs)\n",
    "    all_prompts.extend(astronomy)\n",
    "    all_prompts.extend(science)\n",
    "    all_prompts.extend(science_code_prompts)\n",
    "    all_prompts.extend([\"Generate Python code:\"] * len(code_samples))\n",
    "    \n",
    "    all_codes.extend([\"\"] * (len(scidocs) + len(astronomy) + len(science) + len(science_code_prompts)))\n",
    "    all_codes.extend(code_samples)\n",
    "\n",
    "    # Final dataset\n",
    "    return Dataset.from_dict({\n",
    "        \"prompt\": all_prompts,\n",
    "        \"code\": all_codes\n",
    "    })\n",
    "\n",
    "dataset = prepare_datasets()\n",
    "print(f\"Final dataset size: {len(dataset)}\")\n",
    "print(\"Sample prompts:\", dataset[\"prompt\"][:3])\n",
    "print(\"Sample codes:\", [c[:100] + \"...\" if c else \"\" for c in dataset[\"code\"][-3:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7095cb9b-8687-49f5-bcf9-abfae74692f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 30496\n",
      "Prompt: <|system|>\n",
      "</s>\n",
      "<|user|>\n",
      "safeguards against comets?</s>\n",
      "<|assistant|>\n",
      "\n",
      "Code: \n",
      "\n",
      "Sample 66238\n",
      "Prompt: Generate Python code:\n",
      "Code: from pathlib import Path\n",
      "from typing import Tuple, List, Dict\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from tsfresh.utilities.dataframe_functions import roll_time_series\n",
      "\n",
      "\n",
      "def get_path(df: pd.DataFrame) -> np.array:\n",
      "    out = []\n",
      "    for index, row in df.iterrows():\n",
      "        out.append((row[\"Latitude\"], row[\"Longitude\"]))\n",
      "    return np.array(out)\n",
      "\n",
      "\n",
      "def write_to_csv(path: str, data: Dict[str, List[pd.DataFrame]]) -> None:\n",
      "    full_path: Path\n",
      "    for k, v in data.items():\n",
      "        full_path = Path(path).joinpath(k[: k.find(\"-\")], k[k.find(\"-\") + 1 :])\n",
      "        full_path.mkdir(parents=True, exist_ok=True)\n",
      "        for index, df in enumerate(v):\n",
      "            df.to_csv(full_path.joinpath(\"timeseries-\" + str(index) + \".csv\").open(\"w\"))\n",
      "\n",
      "\n",
      "def to_tsfresh(data_path: str) -> Tuple[pd.DataFrame, pd.Series, pd.Series]:\n",
      "    df = pd.DataFrame()\n",
      "    weight_series = pd.Series()\n",
      "    drivers_series = pd.Series()\n",
      "    temp_df: pd.DataFrame\n",
      "    # ident: str = \"\"\n",
      "    i: int = 0\n",
      "    for placement in {\"deck\", \"stem\"}:\n",
      "        for driver_number in {\"single\", \"double\"}:\n",
      "            for ds in Path(data_path).joinpath(placement, driver_number).iterdir():\n",
      "                temp_df = pd.read_csv(str(ds))\n",
      "                weight = temp_df[\"Weight\"][0]\n",
      "                # ident = placement + \"_\" + driver_number + \"_\" + temp_df[\"Driver\"][0]\n",
      "                temp_df = temp_df.assign(id=i)\n",
      "                temp_df = temp_df.drop(\n",
      "                    [\"Unnamed: 0\", \"Driver\", \"Weight\", \"Placement\"], axis=1\n",
      "                )\n",
      "                df = df.append(temp_df)\n",
      "                weight_series.loc[i] = weight\n",
      "                drivers_series.loc[i] = 0 if driver_number == \"single\" else 1\n",
      "                i += 1\n",
      "    return df.fillna(0), weight_series, drivers_series\n",
      "\n",
      "\n",
      "def window_df(df: pd.DataFrame):\n",
      "    return roll_time_series(\n",
      "        df, column_id=\"id\", column_sort=\"Timestamp\", column_kind=None\n",
      "    )\n",
      "\n",
      "\n",
      "def align(signal_1: np.array, signal_2: np.array):\n",
      "    # Standardization\n",
      "    signal_1 = (signal_1 - np.mean(signal_1)\n",
      "\n",
      "Sample 78908\n",
      "Prompt: Generate Python code:\n",
      "Code: import pandas as pd\n",
      "import numpy as np\n",
      "from scipy.stats import truncnorm\n",
      "from patsy import dmatrix\n",
      "from collections import OrderedDict\n",
      "from hddm.simulators.basic_simulator import *\n",
      "from hddm.model_config import model_config\n",
      "from functools import partial\n",
      "\n",
      "# Helper\n",
      "def hddm_preprocess(\n",
      "    simulator_data=None,\n",
      "    subj_id=\"none\",\n",
      "    keep_negative_responses=False,\n",
      "    add_model_parameters=False,\n",
      "    keep_subj_idx=True,\n",
      "):\n",
      "\n",
      "    \"\"\"Takes simulator data and turns it into HDDM ready format.\n",
      "\n",
      "    :Arguments:\n",
      "        simulator_data: tuple\n",
      "            Output of e.g. the hddm.simulators.basic_simulator function.\n",
      "        subj_id: str <default='none'>\n",
      "            Subject id to attach to returned dataset\n",
      "        keep_negative_responses: bool <default=False>\n",
      "            Whether or not to turn negative responses into 0\n",
      "        add_model_parameters: bool <default=False>\n",
      "            Whether or not to add trial by trial model parameters to returned dataset\n",
      "        keep_subj_idx: bool <default=True>\n",
      "            Whether to keep subject id in the returned dataset\n",
      "\n",
      "    \"\"\"\n",
      "    # Define dataframe if simulator output is normal (comes out as list tuple [rts, choices, metadata])\n",
      "    if len(simulator_data) == 3:\n",
      "        df = pd.DataFrame(simulator_data[0].astype(np.double), columns=[\"rt\"])\n",
      "        df[\"response\"] = simulator_data[1].astype(int)\n",
      "\n",
      "    if not keep_negative_responses:\n",
      "        df.loc[df[\"response\"] == -1.0, \"response\"] = 0.0\n",
      "    if keep_subj_idx:\n",
      "        df[\"subj_idx\"] = subj_id\n",
      "\n",
      "    # Add ground truth parameters to dataframe\n",
      "    if add_model_parameters:\n",
      "        for param in model_config[simulator_data[2][\"model\"]][\"params\"]:\n",
      "            if len(simulator_data[2][param]) > 1:\n",
      "                df[param] = simulator_data[2][param]\n",
      "            else:\n",
      "                # print(param)\n",
      "                # print(simulator_data[2][param][0])\n",
      "                df[param] = simulator_data[2][param][0]\n",
      "    return df\n",
      "\n",
      "\n",
      "def _add_outliers(\n",
      "    sim_out=None,\n",
      "    p_outlier=None,  # AF-comment: Redundant arg\n",
      "\n",
      "Sample 3479\n",
      "Prompt: Generate Python code for: SnapApp: Reducing Authentication Overhead with a Time-Constrained Fast Unlock Option\n",
      "Abstract: We present SnapApp, a novel unlock concept for mobile devices that reduces authentication overhead with a time-constrained quick-access option. SnapApp provides two unlock methods at once: While PIN entry enables full access to the device, users can also bypass authentication with a short sliding gesture (\"Snap\"). This grants access for a limited amount of time (e.g. 30 seconds). The device then a\n",
      "Code: \n",
      "\n",
      "Sample 73564\n",
      "Prompt: Generate Python code:\n",
      "Code: # -*- coding: utf-8 -*-\n",
      "\"\"\"ViPRoPE.ipynb\n",
      "\n",
      "Automatically generated by Colaboratory.\n",
      "\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "import torch, math\n",
      "import torchvision\n",
      "import torchvision.transforms as transforms\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "from PIL import Image\n",
      "!pip install torchsummary\n",
      "from torchsummary import summary\n",
      "import time\n",
      "import torch.nn as nn\n",
      "import torch.nn.functional as F\n",
      "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
      "from torch.utils.data import DataLoader\n",
      "from torch.utils.data import Dataset\n",
      "import torch.optim as optim\n",
      "!pip install torchsummary\n",
      "from torchsummary import summary\n",
      "!pip install einops\n",
      "from math import ceil\n",
      "# !pip install nystrom-attention\n",
      "!pip install performer_pytorch\n",
      "\n",
      "from torch import nn, einsum\n",
      "from einops import rearrange, repeat\n",
      "from einops.layers.torch import Rearrange\n",
      "\n",
      "from torch.cuda.amp import autocast\n",
      "from functools import partial\n",
      "from contextlib import contextmanager\n",
      "from local_attention import LocalAttention\n",
      "from axial_positional_embedding import AxialPositionalEmbedding\n",
      "from performer_pytorch.reversible import ReversibleSequence, SequentialSequence\n",
      "\n",
      "# helpers\n",
      "from einops import reduce\n",
      "\n",
      "transform = transforms.Compose(\n",
      "        [transforms.ToTensor(),\n",
      "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
      "\n",
      "batch_size = 192\n",
      "\n",
      "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
      "                                        download=True, transform=transform)\n",
      "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
      "                                          shuffle=True, num_workers=2)\n",
      "\n",
      "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
      "                                       download=True, transform=transform)\n",
      "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
      "                                         shuffle=False, num_workers=2)\n",
      "\n",
      "classes = ('plane', 'car', 'bird', 'cat',\n",
      "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
      "\n",
      "device = torch.device(\"cuda:0\" \n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "indices = random.sample(range(len(dataset)), 5)\n",
    "\n",
    "for i in indices:\n",
    "    sample = dataset[i]\n",
    "    print(f\"\\nSample {i + 1}\")\n",
    "    print(\"Prompt:\", sample[\"prompt\"])\n",
    "    print(\"Code:\", sample[\"code\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9164fae0-f3ed-4ab7-9c50-75bd90ef3a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,126,400 || all params: 1,101,174,784 || trainable%: 0.1023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|███████████████████████████████████████████████████████████████████████████████████████| 85000/85000 [00:24<00:00, 3476.14 examples/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "model_name = \"TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()  # ~1M parameters\n",
    "\n",
    "def tokenize_func(examples):\n",
    "    combined = [p + \"\\n\" + c for p, c in zip(examples[\"prompt\"], examples[\"code\"])]\n",
    "    return tokenizer(\n",
    "        combined,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512,  # Reduced context for efficiency\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "tokenized_dataset = dataset.map(\n",
    "    tokenize_func, \n",
    "    batched=True,\n",
    "    remove_columns=[\"prompt\", \"code\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a116281-8d9e-4fe7-bb2a-7066175f205e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 1126400\n",
      "Total parameters: 616732672\n",
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3987' max='3987' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3987/3987 4:04:35, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.918600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.904100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.912700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.869100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.801300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.808400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.831900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.787800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.818400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.758500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.756400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.726600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.787700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.763500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.726000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.753300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.745900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.795700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.780400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.783900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.741300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.717900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.766200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.783000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.764500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.726200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.778400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.779300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.758700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.770800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.721200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.763000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.765000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.786900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.754400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.792600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>0.781800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>0.723900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.760200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.746000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>0.765500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.736200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>0.763100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>0.774000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.757100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>0.771400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>0.735100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.782200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>0.781400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.769700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.816400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>0.754600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1060</td>\n",
       "      <td>0.774300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.757100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.764400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120</td>\n",
       "      <td>0.785700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.786900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1160</td>\n",
       "      <td>0.779100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1180</td>\n",
       "      <td>0.762100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.767600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1220</td>\n",
       "      <td>0.779300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1240</td>\n",
       "      <td>0.746900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.763300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1280</td>\n",
       "      <td>0.753500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.768600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.772800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1340</td>\n",
       "      <td>0.709700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1360</td>\n",
       "      <td>0.779100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.763200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.729200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1420</td>\n",
       "      <td>0.715700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.758900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1460</td>\n",
       "      <td>0.752500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1480</td>\n",
       "      <td>0.732200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.757900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1520</td>\n",
       "      <td>0.774200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1540</td>\n",
       "      <td>0.726800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.751000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1580</td>\n",
       "      <td>0.761800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.776000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.748700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1640</td>\n",
       "      <td>0.770200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1660</td>\n",
       "      <td>0.760200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.753100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.777700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1720</td>\n",
       "      <td>0.683200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.739800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1760</td>\n",
       "      <td>0.786400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1780</td>\n",
       "      <td>0.765000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.760900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1820</td>\n",
       "      <td>0.731300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1840</td>\n",
       "      <td>0.776400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.751600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1880</td>\n",
       "      <td>0.770200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.730600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.741700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1940</td>\n",
       "      <td>0.752500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1960</td>\n",
       "      <td>0.755800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1980</td>\n",
       "      <td>0.778700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.768300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020</td>\n",
       "      <td>0.763300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2040</td>\n",
       "      <td>0.760600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2060</td>\n",
       "      <td>0.786200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2080</td>\n",
       "      <td>0.766200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.748100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2120</td>\n",
       "      <td>0.721800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2140</td>\n",
       "      <td>0.754200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2160</td>\n",
       "      <td>0.774300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2180</td>\n",
       "      <td>0.741300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.751400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2220</td>\n",
       "      <td>0.731800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2240</td>\n",
       "      <td>0.785800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2260</td>\n",
       "      <td>0.753800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2280</td>\n",
       "      <td>0.782300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.756100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2320</td>\n",
       "      <td>0.788900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2340</td>\n",
       "      <td>0.736800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2360</td>\n",
       "      <td>0.771600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2380</td>\n",
       "      <td>0.787100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.738100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2420</td>\n",
       "      <td>0.782700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2440</td>\n",
       "      <td>0.719400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2460</td>\n",
       "      <td>0.732700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2480</td>\n",
       "      <td>0.759100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.762400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2520</td>\n",
       "      <td>0.765300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2540</td>\n",
       "      <td>0.762200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2560</td>\n",
       "      <td>0.760700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2580</td>\n",
       "      <td>0.772100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.710300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2620</td>\n",
       "      <td>0.756000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2640</td>\n",
       "      <td>0.763100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2660</td>\n",
       "      <td>0.741800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2680</td>\n",
       "      <td>0.704700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.750100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2720</td>\n",
       "      <td>0.759600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2740</td>\n",
       "      <td>0.762300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2760</td>\n",
       "      <td>0.732900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2780</td>\n",
       "      <td>0.786300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.725700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2820</td>\n",
       "      <td>0.761700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2840</td>\n",
       "      <td>0.711900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2860</td>\n",
       "      <td>0.758400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2880</td>\n",
       "      <td>0.748700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.737300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2920</td>\n",
       "      <td>0.729100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2940</td>\n",
       "      <td>0.776100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2960</td>\n",
       "      <td>0.749000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2980</td>\n",
       "      <td>0.767200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.753900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3020</td>\n",
       "      <td>0.788200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3040</td>\n",
       "      <td>0.723500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3060</td>\n",
       "      <td>0.764400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3080</td>\n",
       "      <td>0.737900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.734100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3120</td>\n",
       "      <td>0.744400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3140</td>\n",
       "      <td>0.731000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3160</td>\n",
       "      <td>0.717200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3180</td>\n",
       "      <td>0.730500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.749800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3220</td>\n",
       "      <td>0.761600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3240</td>\n",
       "      <td>0.732400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3260</td>\n",
       "      <td>0.734500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3280</td>\n",
       "      <td>0.714100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.725900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3320</td>\n",
       "      <td>0.740400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3340</td>\n",
       "      <td>0.745500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3360</td>\n",
       "      <td>0.795100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3380</td>\n",
       "      <td>0.737700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.739300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3420</td>\n",
       "      <td>0.779900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3440</td>\n",
       "      <td>0.769100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3460</td>\n",
       "      <td>0.725200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3480</td>\n",
       "      <td>0.761300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.756900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3520</td>\n",
       "      <td>0.781800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3540</td>\n",
       "      <td>0.737700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3560</td>\n",
       "      <td>0.748000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3580</td>\n",
       "      <td>0.759100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.768600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3620</td>\n",
       "      <td>0.773400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3640</td>\n",
       "      <td>0.704800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3660</td>\n",
       "      <td>0.742500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3680</td>\n",
       "      <td>0.751900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.783700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3720</td>\n",
       "      <td>0.746700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3740</td>\n",
       "      <td>0.727800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3760</td>\n",
       "      <td>0.771800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3780</td>\n",
       "      <td>0.740800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.765900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3820</td>\n",
       "      <td>0.743700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3840</td>\n",
       "      <td>0.729200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3860</td>\n",
       "      <td>0.761900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3880</td>\n",
       "      <td>0.753200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.720400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3920</td>\n",
       "      <td>0.737800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3940</td>\n",
       "      <td>0.739900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3960</td>\n",
       "      <td>0.749100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3980</td>\n",
       "      <td>0.746600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed successfully!\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    "import torch\n",
    "\n",
    "model.gradient_checkpointing_enable()  # Enable before training\n",
    "model.enable_input_require_grads()  # Ensure parameters require gradients\n",
    "model.config.use_cache = False  # Required for gradient checkpointing\n",
    "\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters())}\")\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,\n",
    "    pad_to_multiple_of=8  # Improves performance on modern hardware\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./scientific-codegen\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=8,\n",
    "    learning_rate=2e-4,  # Optimal for LoRA\n",
    "    optim=\"paged_adamw_32bit\",  # Better for 4-bit training\n",
    "    logging_steps=20,\n",
    "    save_strategy=\"epoch\",\n",
    "    fp16=True,\n",
    "    report_to=\"none\",\n",
    "    warmup_ratio=0.1,  # Better than fixed steps\n",
    "    weight_decay=0.01,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    eval_strategy=\"no\",\n",
    "    save_total_limit=2,\n",
    "    gradient_checkpointing=True,\n",
    "    remove_unused_columns=False,  # Important for PEFT models\n",
    "    label_names=[\"input_ids\", \"attention_mask\", \"labels\"]  # Explicitly specify\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "try:\n",
    "    print(\"Starting training...\")\n",
    "    trainer.train()\n",
    "    \n",
    "    trainer.model.save_pretrained(\"./final-model\")\n",
    "    tokenizer.save_pretrained(\"./final-model\")\n",
    "    print(\"Training completed successfully!\")\n",
    "    \n",
    "except RuntimeError as e:\n",
    "    print(f\"Training failed: {str(e)}\")\n",
    "    print(\"Troubleshooting steps:\")\n",
    "    print(\"1. Check dataset format - ensure tokenized_dataset has 'input_ids', 'attention_mask', and 'labels'\")\n",
    "    print(\"2. Reduce batch size or gradient accumulation steps\")\n",
    "    print(\"3. Try without gradient checkpointing\")\n",
    "    print(\"4. Verify model supports training (e.g., not quantized too aggressively)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0f16f118-7dfc-4f27-a624-27bff198885b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating code for classification...\n",
      "\n",
      "Generated Code:\n",
      " import numpy as np\n",
      "from sklearn import tree, ensemble\n",
      "\n",
      "data = [['Lollipop', 0], ['Sandwich', 1], ['Muffin', 3]]\n",
      "classifier = ensemble.RandomForestClassifier(n_estimators=50)\n",
      "classifier.fit(data, y=np.array([False, True]))\n",
      "y_predicted = classifier.predict(data)\n",
      "print(\"Accuracy: \",classification_report(y, y_predicted))\n",
      "\n",
      "Execution Error: __import__ not found\n",
      "\n",
      "Generating code for anomaly detection...\n",
      "\n",
      "Generated Code:\n",
      " import numpy as np\n",
      "from sklearn import preprocessing, svm, model_selection\n",
      "# from scipy.signal import fftconvolve, convolve, convolve2d\n",
      "import matplotlib.pyplot as plt\n",
      "from scipy import signal\n",
      "# import pandas as pd\n",
      "import seaborn as sns\n",
      "sns.set() # set the style of the plot\n",
      "plt.style.use(\"seaborn-dark\")\n",
      "np.random.seed(42)\n",
      "np.seterr(divide='ignore', invalid=\"ignore\", overflow='ignore')\n",
      "\n",
      "# read csv file\n",
      "data = np.loadtxt('../data/iris.csv').T\n",
      "X=data[:,:-1]\n",
      "Y=data[:,-1].reshape((len(data),1))\n",
      "# print (X[0])\n",
      "# X[0], Y[0]\n",
      "# -\n",
      "\n",
      "# split into training and testing sets\n",
      "x_train, x_test, y_train, y_test = model_selection.train_test_split(X, Y, test_size=.33, random_state=0)\n",
      "print (\"Training set size is %i\"% len(y_train))\n",
      "print (\"Testing set size is %i\"% len(y_test))\n",
      "\n",
      "# create a list that will store the results\n",
      "results=[[]]*len(x_test)+[[None]]*len(x_test)\n",
      "for i in range(len(x_test)):\n",
      "    m, t, c, d=model_selection.cross_val_predict(svm.SVC(), x_test[i], y_test[i], cv=5)\n",
      "    result=list(zip(*[(x_test[j][i], y_test[j][i], c)]+[c]))\n",
      "    results[len(result)-1][i]=result\n",
      "\n",
      "# +\n",
      "freq_cutoff = 8   # cutoff frequency [Hz]\n",
      "sr=16000        # sampling rate [kHz]\n",
      "num_fft = 1024  # number of FFT samples\n",
      "n_fft = num_fft     # number of FFT steps\n",
      "hop_length = 128      # hop length [samples]\n",
      "win_length = int(num\n",
      "\n",
      "Execution Error: '(' was never closed (<string>, line 39)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import IsolationForest, RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM  # Fixed import\n",
    "\n",
    "class ScientificCodeGenerator:\n",
    "    def __init__(self, model_path=\"./final-model\"):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_path,\n",
    "            device_map=\"auto\",\n",
    "            torch_dtype=torch.float16\n",
    "        )\n",
    "    \n",
    "    def generate(self, task: str, max_length=512):  # Increased max_length\n",
    "        # Match training prompt format exactly\n",
    "        prompt = f\"Generate Python code for: {task}\\nRequirements:\\n1. Use sklearn/numpy\\n2. Add comments\\n\\nCode:\"\n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.model.device)\n",
    "        \n",
    "        # Proper generation parameters\n",
    "        outputs = self.model.generate(\n",
    "            inputs.input_ids,\n",
    "            max_new_tokens=max_length,\n",
    "            temperature=0.7,  # Higher temperature for creativity\n",
    "            top_p=0.9,         # Nucleus sampling\n",
    "            do_sample=True,     # Enable sampling\n",
    "            num_return_sequences=1,\n",
    "            pad_token_id=self.tokenizer.eos_token_id,\n",
    "            eos_token_id=self.tokenizer.eos_token_id,\n",
    "            repetition_penalty=1.2  # Prevent repetition\n",
    "        )\n",
    "        \n",
    "        # Skip special tokens and remove input prompt\n",
    "        full_output = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        return full_output.replace(prompt, \"\").strip()\n",
    "    \n",
    "    @staticmethod\n",
    "    def execute(code: str, data=None):\n",
    "        \"\"\"Executes generated code safely\"\"\"\n",
    "        # Extract code block\n",
    "        if \"```python\" in code:\n",
    "            code = code.split(\"```python\")[1].split(\"```\")[0]\n",
    "        \n",
    "        # Create restricted environment\n",
    "        restricted_env = {\n",
    "            \"__builtins__\": {},\n",
    "            \"print\": print,\n",
    "            \"np\": np,\n",
    "            \"pd\": pd,\n",
    "            \"plt\": plt,\n",
    "            \"KMeans\": KMeans,\n",
    "            \"IsolationForest\": IsolationForest,\n",
    "            \"RandomForestClassifier\": RandomForestClassifier,\n",
    "            \"data\": data\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            exec(code, restricted_env)\n",
    "            return restricted_env\n",
    "        except Exception as e:\n",
    "            return {\"error\": str(e)}\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize generator\n",
    "    generator = ScientificCodeGenerator()\n",
    "    \n",
    "    # Example 1: Classification\n",
    "    from sklearn.datasets import make_classification\n",
    "    X, y = make_classification(n_samples=100, n_features=4)\n",
    "    data = pd.DataFrame(X, columns=[f\"feature_{i}\" for i in range(4)])\n",
    "    data[\"target\"] = y\n",
    "    \n",
    "    task = \"Classify this data using Random Forest and show accuracy\"\n",
    "    print(\"Generating code for classification...\")\n",
    "    generated_code = generator.generate(task)\n",
    "    print(\"\\nGenerated Code:\\n\", generated_code)\n",
    "    \n",
    "    result = generator.execute(generated_code, data)\n",
    "    if \"accuracy\" in result:\n",
    "        print(f\"\\nClassification Accuracy: {result['accuracy']:.2f}\")\n",
    "    elif \"error\" in result:\n",
    "        print(f\"\\nExecution Error: {result['error']}\")\n",
    "    \n",
    "    # Example 2: Anomaly Detection\n",
    "    from sklearn.datasets import make_blobs\n",
    "    X, _ = make_blobs(n_samples=100, centers=3, cluster_std=1.5)\n",
    "    data = pd.DataFrame(X, columns=[\"x\", \"y\"])\n",
    "    \n",
    "    task = \"Perform anomaly detection on this 2D data\"\n",
    "    print(\"\\nGenerating code for anomaly detection...\")\n",
    "    generated_code = generator.generate(task)\n",
    "    print(\"\\nGenerated Code:\\n\", generated_code)\n",
    "    result = generator.execute(generated_code, data)\n",
    "    \n",
    "    if \"anomalies\" in result:\n",
    "        print(f\"\\nDetected {sum(result['anomalies'])} anomalies\")\n",
    "        plt.scatter(data['x'], data['y'], c=result['anomalies'])\n",
    "        plt.title(\"Anomaly Detection Results\")\n",
    "        plt.show()\n",
    "    elif \"error\" in result:\n",
    "        print(f\"\\nExecution Error: {result['error']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
