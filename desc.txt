Title :
SLMs for specific objectives on resource constrained devices	

Description:
We will work to develop a small language model for a specific objective, e.g. reading machine logs, that can be trained on and do inference on a resource constrained device.

Train and Test Datasets:
https://huggingface.co/datasets/millawell/wikipedia_field_of_science
https://huggingface.co/datasets/David-Xu/astronomy-stack-dpo-text
https://github.com/allenai/scidocs
https://huggingface.co/datasets/bigcode/the-stack

Models Used:
bigcode/tiny_starcoder_py
TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T

Optimization Techinques:
Pruning (both tinyllama and starcoder)
Weight Sharing (only starcoder)
Early Exit (only starcoder)

Results:

TinyLLama:
================================================================================
Optimization Results
================================================================================
 Technique Latency (ms) Throughput (samples/s) Memory (MB) Inference Success (%) Valid Code (%) Execution Success (%) Quality Score
Base Model     10057.68                   0.10      4208.8                 100.0           43.6                  56.9          65.6
   Pruning      5402.01                   0.19      4209.3                 100.0           39.6                  47.5          62.0

StarCoder:
================================================================================
Optimization Results
================================================================================
     Technique Latency (ms) Throughput (samples/s) Memory (MB) Inference Success (%)  Syntax Errors
    Base Model       2664.1                   0.34       731.5                 100.0              5
       Pruning       2737.2                   0.33      1389.7                 100.0              0
Weight Sharing       2711.6                   0.34      1389.9                 100.0              1
    Early Exit       2571.3                   0.36      1390.2                 100.0              3
